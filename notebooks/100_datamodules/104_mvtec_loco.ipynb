{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MVTec LOCO AD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToPILImage\n",
    "\n",
    "from anomalib.data.mvtec_loco import (\n",
    "    MVTecLOCO,\n",
    "    MVTecLOCODataset,\n",
    "    download_and_extract_mvtec_loco,\n",
    ")\n",
    "from anomalib.pre_processing import PreProcessor\n",
    "from anomalib.pre_processing.transforms import Denormalize\n",
    "\n",
    "# make a cell print all the outputs instead of just the last one\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# pylint: disable=locally-disabled, pointless-statement\n",
    "# the ``pointless-statement`` warning is disabled because we use them to print stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and extract the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path(\"../../datasets/MVTecLOCO\")\n",
    "if not root.exists():\n",
    "    download_and_extract_mvtec_loco(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Torch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MVTecLOCODataset??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create `MVTecDataset` we need to import `pre_process` that applies transforms to the input image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PreProcessor??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_process = PreProcessor(image_size=(100, 170), to_tensor=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MVTec LOCO Classification Train Set\n",
    "mvtec_loco_dataset_classification_train = MVTecLOCODataset(\n",
    "    root=\"../../datasets/MVTecLOCO\",\n",
    "    category=\"pushpins\",\n",
    "    split=\"train\",\n",
    "    pre_process=pre_process,\n",
    "    task=\"classification\",\n",
    ")\n",
    "mvtec_loco_dataset_classification_train.samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = mvtec_loco_dataset_classification_train[0]\n",
    "sample.keys()\n",
    "sample[\"image\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen above, when we choose `classification` task and `train` split, the dataset only returns `image`. This is mainly because training only requires normal images and no labels. Now let's try `test` split for the `classification` task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MVTec Classification Test Set\n",
    "mvtec_loco_dataset_classification_test = MVTecLOCODataset(\n",
    "    root=\"../../datasets/MVTecLOCO\",\n",
    "    category=\"pushpins\",\n",
    "    split=\"test\",\n",
    "    pre_process=pre_process,\n",
    "    task=\"classification\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = mvtec_loco_dataset_classification_test[0]\n",
    "sample.keys()\n",
    "sample[\"image\"].shape\n",
    "sample[\"image_path\"]\n",
    "sample[\"label\"]\n",
    "sample[\"super_anotype\"], sample[\"anotype\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negative indices are also enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = mvtec_loco_dataset_classification_test[-1]\n",
    "sample.keys()\n",
    "sample[\"image\"].shape\n",
    "sample[\"image_path\"]\n",
    "sample[\"label\"]\n",
    "sample[\"super_anotype\"], sample[\"anotype\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Segmentation Task\n",
    "\n",
    "It is also possible to configure the MVTec LOCO dataset for the segmentation task, where the dataset object returns image and ground-truth mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MVTec LOCO Segmentation Train Set\n",
    "mvtec_loco_dataset_segmentation_train = MVTecLOCODataset(\n",
    "    root=\"../../datasets/MVTecLOCO\",\n",
    "    category=\"pushpins\",\n",
    "    pre_process=pre_process,\n",
    "    split=\"train\",\n",
    "    task=\"segmentation\",\n",
    ")\n",
    "mvtec_loco_dataset_segmentation_train.samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MVTec LOCO Segmentation Test Set\n",
    "mvtec_loco_dataset_segmentation_test = MVTecLOCODataset(\n",
    "    root=\"../../datasets/MVTecLOCO\",\n",
    "    category=\"pushpins\",\n",
    "    pre_process=pre_process,\n",
    "    split=\"test\",\n",
    "    task=\"segmentation\",\n",
    ")\n",
    "sample = mvtec_loco_dataset_segmentation_test[20]\n",
    "sample.keys()\n",
    "sample[\"image\"].shape\n",
    "sample[\"mask\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the image and the mask..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = ToPILImage()(Denormalize()(sample[\"image\"].clone()))\n",
    "msk = ToPILImage()(sample[\"mask\"]).convert(\"RGB\")\n",
    "\n",
    "Image.fromarray(np.vstack((np.array(img), np.array(msk))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataModule\n",
    "\n",
    "So far, we have shown the Torch Dateset implementation of MVTec LOCO AD dataset. This is quite useful to get a sample, but we do need more than this when we train models in an end-to-end fashion.\n",
    " \n",
    "The [PyTorch Lightning DataModule](https://pytorch-lightning.readthedocs.io/en/latest/data/datamodule.html) for MVTec LOCO AD (shown below) is handles the the dataset download, and train/val/test/inference dataloaders instantiation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MVTecLOCO??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mvtec_datamodule = MVTecLOCO(\n",
    "    root=\"../../datasets/MVTecLOCO\",\n",
    "    category=\"pushpins\",\n",
    "    image_size=(200, 340),  # (height, width) 5x smaller than original\n",
    "    train_batch_size=32,\n",
    "    test_batch_size=32,\n",
    "    num_workers=8,\n",
    "    task=\"segmentation\",\n",
    ")\n",
    "\n",
    "# verify if the dataset is available and download it if not\n",
    "mvtec_datamodule.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train images\n",
    "\n",
    "# instantiate the Torch Dataset(s), loading the (meta-)data into memory\n",
    "mvtec_datamodule.setup(\"fit\")\n",
    "\n",
    "i, data = next(enumerate(mvtec_datamodule.train_dataloader()))\n",
    "data.keys()\n",
    "data[\"image\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation images\n",
    "mvtec_datamodule.setup(\"validate\")\n",
    "i, data = next(enumerate(mvtec_datamodule.val_dataloader()))\n",
    "data.keys()\n",
    "data[\"image\"].shape\n",
    "data[\"mask\"].shape\n",
    "data[\"super_anotype\"][0], data[\"anotype\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test images\n",
    "mvtec_datamodule.setup(\"test\")\n",
    "# iterate a few times so we can find a sample with an anomaly\n",
    "for i, data in enumerate(mvtec_datamodule.test_dataloader()):\n",
    "    if i == 5:\n",
    "        break\n",
    "data.keys()\n",
    "data[\"image\"].shape\n",
    "data[\"mask\"].shape\n",
    "data[\"super_anotype\"][0], data[\"anotype\"][0]\n",
    "\n",
    "img = ToPILImage()(Denormalize()(data[\"image\"][0].clone()))\n",
    "msk = ToPILImage()(data[\"mask\"][0]).convert(\"RGB\")\n",
    "\n",
    "Image.fromarray(np.vstack((np.array(img), np.array(msk))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: show that the ground truth is divided in multiple images\n",
    "\n",
    "TODO: create issue to correct docs in mvtec, e.g. it should not give example in the docstring but send the user\n",
    "      to the notebooks (more maintainable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen above, creating the dataloaders are pretty straghtforward, which could be directly used for training/testing/inference."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('anomalib-dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8787c31053eaf11dad02e12159779e58bcbd87fee611b470525fee7090bb4db2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
